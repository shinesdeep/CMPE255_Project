{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_data():\n",
    "    nvals = 10000   # Change to None for Reading all data\n",
    "    #Read Bureau Balance data and transform to merge with App_train \n",
    "    bureau_bal = pd.read_csv('bureau_balance.csv',nrows=nvals, sep=',', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "    bureau_bal = pd.concat([bureau_bal, pd.get_dummies(bureau_bal.STATUS, prefix='bureau_bal_status')], axis=1).drop('STATUS', axis=1)\n",
    "    bureau_counts = bureau_bal[['SK_ID_BUREAU', 'MONTHS_BALANCE']].groupby('SK_ID_BUREAU').count()\n",
    "    bureau_bal['bureau_count'] = bureau_bal['SK_ID_BUREAU'].map(bureau_counts['MONTHS_BALANCE'])\n",
    "    avg_bureau_bal = bureau_bal.groupby('SK_ID_BUREAU').mean()\n",
    "    avg_bureau_bal.columns = ['avg_' + val for val in avg_bureau_bal.columns]\n",
    "\n",
    "    #Read Bureau Data Transform and Merge with Bureau Balance Data\n",
    "    bureau = pd.read_csv('bureau.csv',nrows=nvals, sep=',', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "    credit_act = pd.get_dummies(bureau.CREDIT_ACTIVE, prefix='ca_')\n",
    "    credit_curr = pd.get_dummies(bureau.CREDIT_CURRENCY, prefix='cu_')\n",
    "    credit_type = pd.get_dummies(bureau.CREDIT_TYPE, prefix='ty_')\n",
    "    bureau_ct = pd.concat([bureau, credit_act, credit_curr, credit_type], axis=1)\n",
    "    bureau_merged = bureau_ct.merge(right=avg_bureau_bal.reset_index(), how='left', on='SK_ID_BUREAU', suffixes=('', '_bureau_bal'))\n",
    "    bureau_per_count = bureau_merged[['SK_ID_CURR', 'SK_ID_BUREAU']].groupby('SK_ID_CURR').count()\n",
    "    bureau_merged['SK_ID_BUREAU'] = bureau_merged['SK_ID_CURR'].map(bureau_per_count['SK_ID_BUREAU'])\n",
    "    bureau_avg = bureau_merged.groupby('SK_ID_CURR').mean()\n",
    "\n",
    "    # Read Previous Application Data and Transform\n",
    "    prev_app = pd.read_csv('previous_application.csv',nrows=nvals, sep=',', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "    categorical_feats = [ cat for cat in prev_app.columns if prev_app[cat].dtype == 'object']\n",
    "    categorical_feats = categorical_feats[2:]\n",
    "    #Factarozise Previous Application data there are so many Object Columns \n",
    "    for cat in categorical_feats:\n",
    "        prev_app[cat],indexer = pd.factorize(prev_app[cat])\n",
    "    prev_app_count = prev_app[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    prev_app['SK_ID_PREV'] = prev_app['SK_ID_CURR'].map(prev_app_count['SK_ID_PREV'])\n",
    "    prev_apps_avg = prev_app.groupby('SK_ID_CURR').mean()\n",
    "    prev_apps_avg.columns = ['prev_' + col for col in prev_apps_avg.columns]\n",
    "\n",
    "    #Read Cash Balance and Transform to merge with App Train Data\n",
    "    pos_cash_bal = pd.read_csv('POS_CASH_balance.csv',nrows=nvals, sep=',', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "    pos_bal = pd.concat([pos_cash_bal, pd.get_dummies(pos_cash_bal['NAME_CONTRACT_STATUS'])], axis=1)\n",
    "    pos_bal_count = pos_bal[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    pos_bal['SK_ID_PREV'] = pos_bal['SK_ID_CURR'].map(pos_bal_count['SK_ID_PREV'])\n",
    "    avg_pos_bal = pos_bal.groupby('SK_ID_CURR').mean()\n",
    "\n",
    "\n",
    "    #Read Credit Balance and Transform to merger with App Train Data\n",
    "    credit_bal = pd.read_csv('credit_card_balance.csv',nrows=nvals, sep=',', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "    credit_bal = pd.concat([credit_bal, pd.get_dummies(credit_bal['NAME_CONTRACT_STATUS'], prefix='credit_status_')], axis=1)\n",
    "\n",
    "    credit_bal_count = credit_bal[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    credit_bal['SK_ID_PREV'] = credit_bal['SK_ID_CURR'].map(credit_bal_count['SK_ID_PREV'])\n",
    "    avg_credit_bal = credit_bal.groupby('SK_ID_CURR').mean()\n",
    "    avg_credit_bal.columns = ['credit_bal_' + f_ for f_ in avg_credit_bal.columns]\n",
    "\n",
    "    # Read Intsallment Payments data and Transform for merging with App Train Data\n",
    "    inst_pay = pd.read_csv('installments_payments.csv',nrows=nvals, sep=',', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "    # As Install Payments as many Object columns get the features and factorize\n",
    "    categorical_feats = [ cat for cat in inst_pay.columns if inst_pay[cat].dtype == 'object']\n",
    "    categorical_feats = categorical_feats[2:]\n",
    "    for cat in categorical_feats:\n",
    "        inst_pay[cat],indexer = pd.factorize(inst_pay[cat])\n",
    "\n",
    "\n",
    "    inst_pay_counts = inst_pay[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    inst_pay['SK_ID_PREV'] = inst_pay['SK_ID_CURR'].map(inst_pay_counts['SK_ID_PREV'])\n",
    "    avg_inst_pay = inst_pay.groupby('SK_ID_CURR').mean()\n",
    "    avg_inst_pay.columns = ['inst_' + f_ for f_ in avg_inst_pay.columns]\n",
    "\n",
    "\n",
    "    # Read Application Training Data and Factorize as many Onject Columns\n",
    "\n",
    "    app_train = pd.read_csv('application_train.csv',nrows=nvals, sep=',', error_bad_lines=False, index_col=False, dtype='unicode')         \n",
    "    y = app_train['TARGET']\n",
    "    del app_train['TARGET']\n",
    "    categorical_feats = [ cat for cat in app_train.columns if app_train[cat].dtype == 'object']\n",
    "    categorical_feats = categorical_feats[1:]\n",
    "    for cat in categorical_feats:\n",
    "        app_train[cat],indexer = pd.factorize(app_train[cat])\n",
    "    # Merger with all the Avg Dara by SKID\n",
    "    app_train_final = app_train.merge(right=bureau_avg.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    app_train_final = app_train_final.merge(right=avg_credit_bal.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    app_train_final = app_train_final.merge(right=prev_apps_avg.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    app_train_final = app_train_final.merge(right=avg_pos_bal.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    app_train_final = app_train_final.merge(right=avg_inst_pay.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    app_train_final = app_train_final.fillna(0)\n",
    "    \n",
    "    print(\"app_train_final\", app_train_final.shape)\n",
    "    return (app_train_final , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def feature_engineering(X,y):\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    rfc=RandomForestClassifier()\n",
    "    rfc.fit(X,y)\n",
    "    Imp = rfc.feature_importances_\n",
    "    ctr = 0\n",
    "    \n",
    "    features_names = []\n",
    "    feature_names = list(X.columns.values)\n",
    "    \n",
    "    Imp = [i * 100 for i in Imp]\n",
    "    cnt = 0\n",
    "    sum = 0.0\n",
    "    for i in Imp:\n",
    "        \n",
    "        sum+=i\n",
    "        if i<0.05:\n",
    "            column_name = feature_names[ctr]\n",
    "            del X[column_name]\n",
    "            cnt += 1\n",
    "        ctr+=1\n",
    "    print(\"Unimportant features : \",cnt)\n",
    "    print(\"Sum : \",sum)\n",
    "    \n",
    "    return (X,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def run_RF(X,y,split):\n",
    "    print(\"\\n ---------------------------------------------\")\n",
    "    print(\"Random forest algorithm\")\n",
    "    print(\"\\n ---------------------------------------------\")\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=split)\n",
    "    clf_rf = RandomForestClassifier(n_estimators=100, max_features='log2')\n",
    "    clf_rf = clf_rf.fit(X_train, y_train)\n",
    "    \n",
    "    cross_val_10 = cross_val_score(clf_rf, X_train, y_train, scoring='accuracy', cv = 10)\n",
    "    cross_val_5 = cross_val_score(clf_rf, X_train, y_train, scoring='accuracy', cv = 5)\n",
    "    \n",
    "    print(\"Cross validation score with cv = 10 : \",cross_val_10.mean())\n",
    "    print(\"Cross validation score with cv = 5 : \",cross_val_5.mean())\n",
    "\n",
    "    y_pred = clf_rf.predict(X_test)\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"\\nAccuracy score for Random Forest:\",accuracy_score(y_test,y_pred))\n",
    "    print(\"\\nF1 score for Random Forest:\",f1_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"\\n---------------------------------------------------------------------------------------------------------------\")\n",
    "    return\n",
    "\n",
    "def run_KNN(X,y,split, k):\n",
    "    print(\"\\n ---------------------------------------------\")\n",
    "    print(\"K-nearest neighbor algorithm\")\n",
    "    print(\" --------------------------------------------- \\n\")\n",
    "    \n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=split)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    \n",
    "    cross_val_10 = cross_val_score(neigh, X_train, y_train, scoring='accuracy', cv = 10)\n",
    "    cross_val_5 = cross_val_score(neigh, X_train, y_train, scoring='accuracy', cv = 5)\n",
    "    \n",
    "    print(\"Cross validation score with cv = 10 : \",cross_val_10.mean())\n",
    "    print(\"Cross validation score with cv = 5 : \",cross_val_5.mean())\n",
    "    \n",
    "    y_pred = neigh.predict(X_test)\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"\\nAccuracy score for KNN:\",accuracy_score(y_test,y_pred))\n",
    "    print(\"\\nF1 score for KNN:\",f1_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"\\n---------------------------------------------------------------------------------------------------------------\")\n",
    "    return  \n",
    "\n",
    "def run_SVM(X, y, split):\n",
    "    print(\"\\n ---------------------------------------------\")\n",
    "    print(\"SVM algorithm\")\n",
    "    print(\" --------------------------------------------- \\n\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=split)\n",
    "    model = svm.SVC(gamma=0.1)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    cross_val_10 = cross_val_score(model, X_train, y_train, scoring='accuracy', cv = 10)\n",
    "    cross_val_5 = cross_val_score(model, X_train, y_train, scoring='accuracy', cv = 5)\n",
    "    \n",
    "    print(\"Cross validation score with cv = 10 : \",cross_val_10.mean())\n",
    "    print(\"Cross validation score with cv = 5 : \",cross_val_5.mean())\n",
    "    \n",
    "    report = classification_report(y_test,y_pred)\n",
    "    print(\"Classification report:\\n%s\" % report)\n",
    "    print(\"Accuracy score for SVM is:\",accuracy_score(y_test,y_pred))\n",
    "    print(\"\\nF1 score for SVM:\",f1_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"\\n---------------------------------------------------------------------------------------------------------------\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ......\n",
      "app_train_final (10000, 202)\n",
      "(10000, 202)\n",
      "(10000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unimportant features :  74\n",
      "Sum :  99.99999999999997\n",
      "After feature_engineering\n",
      "new_x :  (10000, 128)\n",
      "new_y :  (10000,)\n",
      "\n",
      " ---------------------------------------------\n",
      "Random forest algorithm\n",
      "\n",
      " ---------------------------------------------\n",
      "Cross validation score with cv = 10 :  0.9250008673487089\n",
      "Cross validation score with cv = 5 :  0.925\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2750\n",
      "           1       0.00      0.00      0.00       250\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      3000\n",
      "   macro avg       0.46      0.50      0.48      3000\n",
      "weighted avg       0.84      0.92      0.88      3000\n",
      "\n",
      "\n",
      "Accuracy score for Random Forest: 0.9166666666666666\n",
      "\n",
      "F1 score for Random Forest: 0.8768115942028986\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------------------------------------------\n",
      "K-nearest neighbor algorithm\n",
      " --------------------------------------------- \n",
      "\n",
      "Cross validation score with cv = 10 :  0.9068561743420467\n",
      "Cross validation score with cv = 5 :  0.9055713067783635\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      2771\n",
      "           1       0.11      0.02      0.04       229\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      3000\n",
      "   macro avg       0.52      0.50      0.49      3000\n",
      "weighted avg       0.86      0.91      0.88      3000\n",
      "\n",
      "\n",
      "Accuracy score for KNN: 0.9113333333333333\n",
      "\n",
      "F1 score for KNN: 0.8835086541285613\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "\n",
      " ---------------------------------------------\n",
      "SVM algorithm\n",
      " --------------------------------------------- \n",
      "\n",
      "Cross validation score with cv = 10 :  0.9343568658326772\n",
      "Cross validation score with cv = 5 :  0.9342945339776811\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       276\n",
      "           1       0.00      0.00      0.00        24\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       300\n",
      "   macro avg       0.46      0.50      0.48       300\n",
      "weighted avg       0.85      0.92      0.88       300\n",
      "\n",
      "Accuracy score for SVM is: 0.92\n",
      "\n",
      "F1 score for SVM: 0.8816666666666667\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Running ......\") \n",
    "\n",
    "X,y = read_data()\n",
    "new_x, new_y = feature_engineering(X,y)\n",
    "print(\"After feature_engineering\")\n",
    "print(\"new_x : \",new_x.shape)\n",
    "print(\"new_y : \",new_y.shape)\n",
    "# print(\"Calling the Random forest algorithm and prediction\")\n",
    "run_RF(X, y, 0.3)\n",
    "run_KNN(X, y, 0.3, 3)\n",
    "run_SVM(X[:1000], y[:1000], 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------------------------------------------\n",
      "Random forest algorithm\n",
      "\n",
      " ---------------------------------------------\n",
      "Cross validation score with cv = 10 :  0.9244287448983133\n",
      "Cross validation score with cv = 5 :  0.9244286580904232\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2754\n",
      "           1       0.00      0.00      0.00       246\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      3000\n",
      "   macro avg       0.46      0.50      0.48      3000\n",
      "weighted avg       0.84      0.92      0.88      3000\n",
      "\n",
      "\n",
      "Accuracy score for Random Forest: 0.918\n",
      "\n",
      "F1 score for Random Forest: 0.8787528675703858\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "\n",
      " ---------------------------------------------\n",
      "K-nearest neighbor algorithm\n",
      " --------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score with cv = 10 :  0.9062855976674007\n",
      "Cross validation score with cv = 5 :  0.90842935014617\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      2758\n",
      "           1       0.14      0.03      0.05       242\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      3000\n",
      "   macro avg       0.53      0.51      0.50      3000\n",
      "weighted avg       0.86      0.91      0.88      3000\n",
      "\n",
      "\n",
      "Accuracy score for KNN: 0.905\n",
      "\n",
      "F1 score for KNN: 0.8776465300492772\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "\n",
      " ---------------------------------------------\n",
      "SVM algorithm\n",
      " --------------------------------------------- \n",
      "\n",
      "Cross validation score with cv = 10 :  0.9372140086898201\n",
      "Cross validation score with cv = 5 :  0.9371518226148565\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       274\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       300\n",
      "   macro avg       0.46      0.50      0.48       300\n",
      "weighted avg       0.83      0.91      0.87       300\n",
      "\n",
      "Accuracy score for SVM is: 0.9133333333333333\n",
      "\n",
      "F1 score for SVM: 0.8719628339140534\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "run_RF(new_x, new_y, 0.3)\n",
    "run_KNN(new_x, new_y, 0.3, 3)\n",
    "run_SVM(new_x[:1000], new_y[:1000], 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
